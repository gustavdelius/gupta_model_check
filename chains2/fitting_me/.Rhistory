prev_flight_all_cities_FINAL_2 %>% filter(origin_city == "Beijing" & daily_prevalence == 0)
prev_flight_all_cities_FINAL_2 %>% filter(origin_city == "Beijing" & daily_prevalence == max(daily_prevalence))
prev_flight_all_cities_FINAL_2 %>% filter(origin_city == "Beijing") %>% filter(daily_prevalence == max(daily_prevalence))
22000000*0.0000270
prev_flight_all_cities_FINAL_2 %>% filter(origin_city == "BeijChangshaing") %>% filter(daily_prevalence == max(daily_prevalence))
prev_flight_all_cities_FINAL_2 %>% filter(origin_city == "Changsha") %>% filter(daily_prevalence == max(daily_prevalence))
7500000*0.000269
risk_all_cities<-prev_flight_all_cities_FINAL_2%>%
mutate(prev_vol_product=((daily_prevalence*daily_volume)/0.092))%>%
group_by(destination_country,origin_city)%>%
summarise(export_risk=sum(prev_vol_product))%>%
mutate(risk_importation=exp(scaling_factor)*export_risk)%>%
group_by(destination_country)%>%
summarise(num_exp_dest=sum(risk_importation))
risk_all_cities
library(tidyverse)
risk_wuhan_confirmed_cases <- read_csv("~/Downloads/risk_wuhan_confirmed_cases.csv")
reg_risk_wuhan<-glm(confirmed_cases_scaled~offset(log(risk_importation)),
data=risk_wuhan_confirmed_cases, family=poisson(link="log"))
summary(reg_risk_wuhan)
scaling_factor<-coefficients(reg_risk_wuhan)[[1]]
prev_flight_all_cities_FINAL_2 <- read_csv("~/Downloads/prev_flight_all_cities_FINAL_2.csv")
risk_all_cities<-prev_flight_all_cities_FINAL_2%>%
mutate(prev_vol_product=((daily_prevalence*daily_volume)/0.092))%>%
group_by(destination_country,origin_city)%>%
summarise(export_risk=sum(prev_vol_product))%>%
mutate(risk_importation=exp(scaling_factor)*export_risk)%>%
group_by(destination_country)%>%
summarise(num_exp_dest=sum(risk_importation))
risk
risk_all_cities
unique(prev_flight_all_cities_FINAL_2$origin_city)
head(prev_flight_all_cities_FINAL_2)
prev_flight_all_cities_FINAL_2 %>% ggplot() + goem_line(aes(x=date,y=products)) + facet_wrap(~province)
prev_flight_all_cities_FINAL_2 %>% ggplot() + geom_line(aes(x=date,y=products)) + facet_wrap(~province)
prev_flight_all_cities_FINAL_2 %>% ggplot() + geom_line(aes(x=date,y=products)) + facet_wrap(~origin_city)
prev_flight_all_cities_FINAL_2 %>% ggplot() + geom_line(aes(x=date,y=products)) + facet_grid(destination_country~origin_city)
prev_flight_all_cities_FINAL_2 %>% ggplot() + geom_line(aes(x=date,y=products)) + facet_grid(origin_city~destination_country)
0.005
risk_all_cities<-prev_flight_all_cities_FINAL_2%>%
mutate(prev_vol_product=((daily_prevalence*daily_volume)))%>%
group_by(destination_country,origin_city)%>%
summarise(export_risk=sum(prev_vol_product))%>%
mutate(risk_importation=exp(scaling_factor)*export_risk)%>%
group_by(destination_country)%>%
summarise(num_exp_dest=sum(risk_importation))
prev_flight_all_cities_FINAL_2 %>% ggplot() + geom_line(aes(x=date,y=products)) + facet_grid(origin_city~destination_country)\
prev_flight_all_cities_FINAL_2 %>% ggplot() + geom_line(aes(x=date,y=products)) + facet_grid(origin_city~destination_country)
risk_all_cities<-prev_flight_all_cities_FINAL_2%>%
mutate(prev_vol_product=((daily_prevalence*daily_volume)))%>%
group_by(destination_country,origin_city)%>%
summarise(export_risk=sum(prev_vol_product))%>%
mutate(risk_importation=exp(scaling_factor)*export_risk)%>%
group_by(destination_country)%>%
summarise(num_exp_dest=sum(risk_importation))
prev_flight_all_cities_FINAL_2 %>% ggplot() + geom_line(aes(x=date,y=products)) + facet_grid(origin_city~destination_country)
prev_flight_all_cities_FINAL_2%>%
mutate(prev_vol_product=((daily_prevalence*daily_volume)))%>%
group_by(destination_country,origin_city)%>%
summarise(export_risk=sum(prev_vol_product))
scaling_factor
exp(scaling_factor)
head(prev_flight_all_cities_FINAL_2)
risk_all_cities
risk_all_cities<-prev_flight_all_cities_FINAL_2%>%
mutate(prev_vol_product=((daily_prevalence*daily_volume)))
risk_all_cities<-prev_flight_all_cities_FINAL_2%>%
mutate(prev_vol_product=((daily_prevalence*daily_volume)))
risk_all_cities
ggplot(risk_all_cities) + geom_line(aes(x=date,y=prev_vol_product))
ggplot(risk_all_cities) + geom_line(aes(x=date,y=prev_vol_product)) + facet_grid(origin_city~destination_country)
ggplot(risk_all_cities) + geom_line(aes(x=date,y=cumsum(prev_vol_product))) + facet_grid(origin_city~destination_country)
risk_all_cities<-prev_flight_all_cities_FINAL_2%>%
mutate(prev_vol_product=((daily_prevalence*daily_volume)))%>%
group_by(destination_country,origin_city)%>%
summarise(export_risk=sum(prev_vol_product))%>%
mutate(risk_importation=exp(scaling_factor)*export_risk)%>%
group_by(destination_country)%>%
summarise(num_exp_dest=sum(risk_importation))
risk_all_cities
risk_all_cities<-prev_flight_all_cities_FINAL_2%>%
mutate(prev_vol_product=((daily_prevalence*daily_volume)))%>%
group_by(destination_country,origin_city)%>%
summarise(export_risk=sum(prev_vol_product))
risk_all_cities
- read_csv("~/Downloads/prev_flight_all_cities_FINAL_2.csv")
risk_all_cities<-prev_flight_all_cities_FINAL_2%>%
mutate(prev_vol_product=((daily_prevalence*daily_volume)))
ggplot(risk_all_cities) + geom_line(aes(x=date,y=cumsum(prev_vol_product))) + facet_grid(origin_city~destination_country)
risk_all_cities %>% filter(origin_city == "Beijing" & destination_country == "Egpyt")
risk_all_cities %>% filter(origin_city == "Beijing" & destination_country == "Egypt")
risk_all_cities %>% filter(origin_city == "Beijing" & destination_country == "Egypt") %>% pull(prev_vol_product)
risk_all_cities %>% filter(origin_city == "Beijing" & destination_country == "Egypt") %>% pull(prev_vol_product) %>% sum
risk_all_cities %>% filter(origin_city == "Beijing" & destination_country == "Egypt") %>% pull(prev_vol_product) %>% cumsum
2000/2000000
2000/2000000*100
2000/200000*100
install.packages("lognorm")
library(lognorm)
getLognormMode(1.57,0.65)
plot(dlnorm(0:30,1.57, 0.65))
mean(rlnorm(1000,1.57,0.65))
sd(rlnorm(1000,1.57,0.65))
x <- (rlnorm(1000,1.57,0.65))
dens(density(x))
dens <- density(x)
dens$x[which.max(dens$y)]
exp(1.57 - 0.67^2)
exp(1.57 - 0.65^2)
library(lazymcmc)
run_MCMC
devtools::install_github("jameshay218/lazymcmc",ref="parallel_tempering")
devtools::install_github("jameshay218/lazymcmc",ref="parallel_tempering")
devtools::install_github("jameshay218/lazymcmc",ref="parallel_tempering",force=TRUE)
library(lazymcmc)
run_MCMC
#devtools::install_github("jameshay218/lazymcmc",ref="parallel_tempering")
#library(lazymcmc)
devtool::load_all("~/Documents/GitHub/lazymcmc/")
#devtools::install_github("jameshay218/lazymcmc",ref="parallel_tempering")
#library(lazymcmc)
devtools::load_all("~/Documents/GitHub/lazymcmc/")
run_MCMC
hist(rgamma(1000, 5, rate=5/0.01))
hist(rgamma(1000, 5, rate=5/0.001))
hist(rnorm(1000, 4.5, 1))
hist(rnorm(10000, 2.5,1))
hist(rnorm(10000, 2.5,0.5))
hist(rnorm(10000, 1/4.5,1))
hist(1/rnorm(10000, 1/4.5,1))
rnorm(10000, 1/4.5,1)
1/rnorm(10000, 1/4.5,1)
hist(1/rnorm(10000, 1/4.5,1))
hist(1/rnorm(10000, 1/4.5,1),xlim=c(0,100))
hist(rgamma(1000,shape=5,rate=5/0.001))
hist(rgamma(1000,shape=5,rate=50/0.001))
gamma_pars_from_mean_sd(0.01,0.1)
gamma_pars_from_mean_sd <- function(gamma_mean, gamma_var){
scale <- gamma_var/gamma_mean
shape <- gamma_mean/scale
return(list("shape"=shape,"scale"=scale))
}
gamma_pars_from_mean_sd(0.01,0.1)
hist(rgamma(1000,shape=0.001, scale=10))
gamma_pars_from_mean_sd(0.01,0.01)
hist(rgamma(1000,shape=0.001, scale=10))
hist(rgamma(1000,shape=0.01, scale=1))
gamma_pars_from_mean_sd(0.01,0.001)
hist(rgamma(1000,shape=0.01, scale=1))
gamma_pars_from_mean_sd(0.1,0.001)
hist(rgamma(1000,shape=0.01, scale=1))
gamma_pars_from_mean_sd(1,0.001)
hist(rgamma(1000,shape=0.01, scale=1))
gamma_pars_from_mean_sd(0.01,0.0001)
hist(rgamma(1000,shape=0.01, scale=1))
g_pars <- gamma_pars_from_mean_sd(0.01,0.0001)
hist(rgamma(1000,shape=g_pars[[1]], scale=g_pars[[2]]))
g_pars <- gamma_pars_from_mean_sd(0.01,0.001)
hist(rgamma(1000,shape=g_pars[[1]], scale=g_pars[[2]]))
hist(rgamma(1000,shape=g_pars[[1]], scale=g_pars[[2]]),breaks=100)
hist(rnorm(10000, 2.5,0.5))
hist(rnorm(10000, 1/4.5,1))
gamma_pars_from_mean_sd <- function(gamma_mean, gamma_var){
scale <- gamma_var/gamma_mean
shape <- gamma_mean/scale
return(list("shape"=shape,"scale"=scale))
}
g_pars <- gamma_pars_from_mean_sd(0.01,0.001)
hist(rgamma(1000,shape=g_pars[[1]], scale=g_pars[[2]]),breaks=100)
chain <- read.csv("SIR_fitting_multivariate_chain.csv")
plot(coda::as.mcmc(chain))
hist(1/chain$sigma)
plot(coda::as.mcmc(chain))
chain <- read.csv("SIR_fitting_multivariate_chain.csv")
plot(coda::as.mcmc(chain[chain$sampno > 10000,]))
plot(chain$R0 ~ chain$sigma)
plot(chain$rho ~ chain$sigma)
chain <- read.csv("SIR_fitting_multivariate_chain.csv")
chain <- chain[chain$sampno > 10000,]
plot(chain$rho ~ chain$sigma)
chain <- read.csv("SIR_fitting_univariate_chain.csv")
plot(coda::as.mcmc(chain))
chain <- read.csv("SIR_fitting_univariate_chain.csv")
plot(coda::as.mcmc(chain))
chain <- read.csv("SIR_fitting_univariate_chain.csv")
plot(coda::as.mcmc(chain))
plot(chain$R0~chain$sigma
)
plot(chain$R0~chain$rho)
plot(chain$sigma~chain$rho)
1/0.15
chain <- read.csv("SIR_fitting_base_univariate_chain.csv")
plot(coda::as.mcmc(chain))
chain <- read.csv("SIR_fitting_base_univariate_chain.csv")
plot(coda::as.mcmc(chain[chain$sampno > 10000,]))
chain <- read.csv("SIR_fitting_multivariate_chain.csv")
plot(coda::as.mcmc(chain[chain$sampno > 1000,]))
plot(coda::as.mcmc(chain[chain$sampno > 1000,]))
chain <- read.csv("SIR_fitting_multivariate_chain.csv")
plot(coda::as.mcmc(chain[chain$sampno > 1000,]))
chain <- read.csv("SIR_fitting_multivariate_chain.csv")
plot(coda::as.mcmc(chain[chain$sampno > 1000,]))
chain <- read.csv("SIR_fitting_multivariate_chain.csv")
plot(coda::as.mcmc(chain[chain$sampno > 1000,]))
chain <- read.csv("SIR_fitting_base_multivariate_chain.csv")
plot(coda::as.mcmc(chain[chain$sampno > 1000,]))
1/0.3
plot(coda::as.mcmc(chain[chain$sampno > 1000,]))
plot(coda::as.mcmc(chain[chain$sampno > 1000,]))
chain <- read.csv("SIR_fitting_multivariate_chain.csv")
plot(coda::as.mcmc(chain[chain$sampno > 1000,]))
chain <- read.csv("SIR_fitting_multivariate_chain.csv")
plot(coda::as.mcmc(chain[chain$sampno > 1000,]))
hist(rnorm(1000,0.05,1))
chain <- read.csv("SIR_fitting_multivariate_chain.csv")
plot(coda::as.mcmc(chain[chain$sampno > 1000,]))
setwd("~/Documents/GitHub/gupta_model_check/")
setwd("~/Documents/GitHub/gupta_model_check/chains/fitting_lourenco/")
chain <- read.csv("fitting_lourenco_1_multivariate_chain.csv")
chain <- read.csv("fitting_lourenco_1_univariate_chain.csv")
plot(coda::as.mcmc(chain))
setwd("~/Documents/GitHub/gupta_model_check/chains/fitting_me/")
chain <- read.csv("fitting_me_1_univariate_chain.csv")
plot(coda::as.mcmc(chain))
chain <- read.csv("fitting_me_1_multivariate_chain.csv")
plot(coda::as.mcmc(chain))
setwd("~/Documents/GitHub/gupta_model_check/chains/fitting_me/")
chain <- read.csv("fitting_me_1_multivariate_chain.csv")
plot(coda::as.mcmc(chain))
setwd("~/Documents/GitHub/gupta_model_check/chains/prior_only_me/")
chain <- read.csv("prior_only_me_1_multivariate_chain.csv")
plot(coda::as.mcmc(chain))
setwd("~/Documents/GitHub/gupta_model_check/chains/fitting_me/")
chain <- read.csv("fitting_me_1_multivariate_chain.csv")
plot(coda::as.mcmc(chain))
plot(coda::as.mcmc(chain))
plot(chain$t0~chain$rho)
par(mfrow=c(1,1))
par(ask=FALSE)
plot(chain$t0~chain$rho)
plot(chain$t0~chain$R0)
setwd("~/Documents/GitHub/gupta_model_check/chains/fitting_lourenco/")
setwd("~/Documents/GitHub/gupta_model_check/chains/fitting_lourenco/")
chain <- read.csv("fitting_lourenco_1_multivariate_chain.csv")
plot(coda::as.mcmc(chain))
1/0.3
setwd("~/Documents/GitHub/gupta_model_check/chains/fitting_lourenco/")
chain <- read.csv("fitting_lourenco_1_multivariate_chain.csv")
plot(coda::as.mcmc(chain))
setwd("~/Documents/GitHub/gupta_model_check/chains/fitting_me/")
chain <- read.csv("fitting_lourenco_1_univariate_chain.csv")
plot(coda::as.mcmc(chain))
setwd("~/Documents/GitHub/gupta_model_check/chains/fitting_me/")
chain <- read.csv("fitting_lourenco_1_univariate_chain.csv")
chain <- read.csv("fitting_me_1_univariate_chain.csv")
plot(coda::as.mcmc(chain))
setwd("~/Documents/GitHub/gupta_model_check/chains/fitting_lourenco/")
chain <- read.csv("fitting_lourenco_1_multivariate_chain.csv")
plot(coda::as.mcmc(chain))
setwd("~/Documents/GitHub/gupta_model_check/chains/prior_only_me/")
chain <- read.csv("prior_only_me_1_multivariate_chain.csv")
plot(coda::as.mcmc(chain))
setwd("~/Documents/GitHub/gupta_model_check/chains/fitting_me/")
chain <- read.csv("fitting_me_1_univariate_chain.csv")
plot(coda::as.mcmc(chain))
setwd("~/Documents/GitHub/gupta_model_check/chains/fitting_me/")
chain <- read.csv("fitting_me_1_univariate_chain.csv")
plot(coda::as.mcmc(chain))
setwd("~/Documents/GitHub/gupta_model_check/chains/prior_only_me/")
chain <- read.csv("prior_only_me_1_multivariate_chain.csv")
plot(coda::as.mcmc(chain))
setwd("~/Documents/GitHub/gupta_model_check/chains/fitting_me/")
chain <- read.csv("fitting_me_1_univariate_chain.csv")
plot(coda::as.mcmc(chain))
setwd("~/Documents/GitHub/gupta_model_check/chains/fitting_lourenco/")
chain <- read.csv("fitting_lourenco_1_multivariate_chain.csv")
plot(coda::as.mcmc(chain))
setwd("~/Documents/GitHub/gupta_model_check/chains/fitting_me/")
chain <- read.csv("fitting_me_2_univariate_chain.csv")
plot(coda::as.mcmc(chain))
max(chain$sampno)
chain <- read.csv("fitting_me_1_multivariate_chain.csv")
plot(coda::as.mcmc(chain))
max(chain$sampno)
setwd("~/Documents/GitHub/gupta_model_check/chains/fitting_me/")
chain <- read.csv("fitting_me_1_multivariate_chain.csv")
plot(coda::as.mcmc(chain))
chain <- read.csv("fitting_me_2_multivariate_chain.csv")
plot(coda::as.mcmc(chain))
chain <- read.csv("fitting_me_3_multivariate_chain.csv")
plot(coda::as.mcmc(chain))
setwd("~/Documents/GitHub/gupta_model_check/chains/fitting_lourenco/")
chain <- read.csv("fitting_lourenco_1_multivariate_chain.csv")
plot(coda::as.mcmc(chain))
chain <- read.csv("fitting_me_3_multivariate_chain.csv")
setwd("~/Documents/GitHub/gupta_model_check/chains/fitting_me/")
chain <- read.csv("fitting_me_3_multivariate_chain.csv")
plot(coda::as.mcmc(chain))
plot(chain$rho~chain$t0)
plot(chain$rho~chain$R0)
plot(chain$rho~chain$sigma)
plot(chain$R0~chain$sigma)
plot(chain$t0~chain$rho)
plot(chain$R0~(1/chain$sigma))
x <- 1/chain$sigma
plot(chain$rho ~ x)
plot(chain$R0 ~ x)
plot(chain$rho ~ chain$t0)
plot(x ~ chain$t0)
head(chain)
pairs(chain[,2:(ncol(chain)-1)])
\
chain1 <- chain[seq(1,nrow(chain),by=100),c("R0","sigma","rho","theta","psi","t0")]
pairs(chain1)
chain1 <- chain[seq(1,nrow(chain),by=10),c("R0","sigma","rho","theta","psi","t0")]
pairs(chain1)
png("correlations.png",height=7,width=7,units="in",res=300)
pairs(chain1)
dev.off()
getwd()
all_runs <- list.files()
all_chains <- NULL
for(run in all_runs){
chains <- load_mcmc_chains(paste0(top_wd, "/chains/",run),parTab,TRUE,10,mcmcPars2["adaptive_period"])
tmp_chain <- as.data.frame(chains[[2]])
tmp_chain$sampno <- 1:nrow(tmp_chain)
tmp_chain$run <- run
tmp_chain <- reshape2::melt(tmp_chain, id.vars=c("sampno","run"))
all_chains <- rbind(all_chains, tmp_chain)
}
library(lazymcmc)
setwd(top_wd)
top_wd <- "~/Documents/GitHub/gupta_model_check/"
setwd(top_wd)
setwd("chains")
all_runs <- list.files()
all_chains <- NULL
for(run in all_runs){
chains <- load_mcmc_chains(paste0(top_wd, "/chains/",run),parTab,TRUE,10,mcmcPars2["adaptive_period"])
tmp_chain <- as.data.frame(chains[[2]])
tmp_chain$sampno <- 1:nrow(tmp_chain)
tmp_chain$run <- run
tmp_chain <- reshape2::melt(tmp_chain, id.vars=c("sampno","run"))
all_chains <- rbind(all_chains, tmp_chain)
}
mcmcPars1 <- c("iterations"=50000,"popt"=0.44,"opt_freq"=1000,
"thin"=10,"adaptive_period"=20000,"save_block"=1000)
mcmcPars2 <- c("iterations"=200000,"popt"=0.234,"opt_freq"=1000,
"thin"=10,"adaptive_period"=100000,"save_block"=1000)
runnames <- c("prior_only_lourenco","prior_only_me","fitting_lourenco","fitting_me")
n_runs <- length(runnames)
prior_controls <- c(TRUE,TRUE,FALSE,FALSE)
prior_use <- c(1,2,1,2)
n_chains <- 3
runnames <- rep(runnames, each=n_chains)
prior_controls <- rep(prior_controls,each=n_chains)
prior_use <- rep(prior_use, each=n_chains)
chain_nos <- rep(1:n_chains, n_runs)
## Define the set of ODEs for the model. Return such that we can solve with deSolve
SIR_odes <- function(t, x, params) {
y <- x[1]
z <- x[2]
dead <- x[3]
## Extract model parameters
R0 <- params[1]
sigma <- params[2]
rho <- params[3]
theta <- params[4]
N <- params[5]
beta <- R0*sigma
dY <- beta*y*(1-z) - sigma*y
dZ <- beta*y*(1-z)
## Note need to shift this number forward by psi days post-hoc
dDead <- N*rho*theta*z
list(c(dY,dZ,dDead))
}
## ROUGH PARAMETERS FROM THE PAPER
sigma <- 1/3.25 ## 1/Infectious period
R0 <- 2.25 ## Basic reproductive number
rho <- 0.001 ## Proportion of population at risk of severe disease
theta <- 0.14 ## Probability of dying with severe disease
psi <- 17 ## Time between infection and death
t0 <- 0
psi <- 15.5
## Population of UK
N <- 66800000
## EXTRACT AND CLEAN DATA
## Number dead in UK to date
obs_deaths <- read_csv("~/Documents/GitHub/COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv")
obs_deaths <- obs_deaths %>% filter(`Country/Region` == "United Kingdom") %>% select(-c("Province/State","Country/Region","Lat","Long"))
obs_deaths <- colSums(obs_deaths)
obs_deaths <- data.frame(time=names(obs_deaths),dead=obs_deaths)
obs_deaths$time <- as.Date(as.character(obs_deaths$time),origin="2020-01-01", format="%m/%d/%y")
obs_deaths <- obs_deaths %>% filter(time <= "2020-03-19")
obs_deaths <- obs_deaths %>% filter(time >= "2020-03-05")
data <- obs_deaths
## Take a look to see that model makes sense
## Times to solve model over
t <- seq(0,100,by=1)
## Note starting conditions for population size - we're working per capita here
results <- as.data.frame(deSolve::ode(y=c(y=1/N,z=1/N,Dead=0),
times=t, func=SIR_odes,
parms=c(R0,sigma, rho, theta, N)))
## Deaths for that time are actually reported psi days later
results$time_deaths <- results$time + psi
results$susc <- 1 - results$z
results$time <- as.Date(results$time, origin="2020-01-27")
plot(results[,c("time","susc")], type='l',col="green",xlab="Time (days)", ylab="Proportion of population",ylim=c(0,1))
lines(results[,c("time","z")],col="blue")
lines(results[,c("time","y")],col="red")
abline(v=as.Date(results[results$Dead > 1,][1,"time_deaths"],origin="2020-01-27"),lty=2)
legend("topright", title="Key",
legend=c("Proportion infectious","Proportion no longer susceptible","Proportion susceptible"),
col=c("red","blue","green"),
lty=c(1,1,1))
##################################
## NOW SET UP CODE TO FIT MODEL
t_long <- seq(0,365,by=1)
pars <- c(R0, sigma, rho, theta, N, psi, t0)
names(pars) <- c("R0","sigma","rho","theta","N","psi","t0")
## Putting model solving code in a function for later use
solve_model <- function(pars, t){
N <- pars["N"]
psi <- pars["psi"]
t0 <- pars["t0"]
## Note starting conditions for population size - we're working per capita here
results <- as.data.frame(deSolve::ode(y=c(y=1/N,z=1/N,Dead=0),
times=t, func=SIR_odes,
parms=pars))
## For solve deaths, shift forward in time as will only be observed
## t0 + psi days after t=0
## Find first day of >1 integer death
predicted <- results %>%
mutate(time = as.integer(time + t0 + psi)) %>%
mutate(time = as.Date(time, origin="2020-01-01"))
return(predicted)
}
## We need to put our likleihood function in a closure environment
## It's important to write the function in this form!
create_lik <- function(parTab, data, PRIOR_FUNC,t, PRIOR_ONLY=FALSE){
par_names <- parTab$names
## Extract observed incidence
obs_dead <- data$dead
max_time <- max(data$time)
min_time <- min(data$time)
likelihood_func <- function(pars){
names(pars) <- par_names
## Solve model
if(!PRIOR_ONLY){
predicted <- solve_model(pars, t)
## Get deaths that match data
predicted1 <-  predicted %>%
filter(time <= max_time & time >= min_time) %>% pull(Dead)
lik <- sum(dpois(x=obs_dead,lambda=predicted1,log=TRUE))
} else {
lik <- 0
}
if(!is.null(PRIOR_FUNC)) lik <- lik + PRIOR_FUNC(pars)
lik
}
}
## Control parameters in MCMC
parTab <- data.frame(names=c("R0","sigma", "rho", "theta", "N", "psi", "t0"),
values=pars,
fixed=c(0,0,0,0,1,0,0),
steps=c(0.1,0.1,0.1,0.1,0.1,0.1,0.1),
lower_bound=c(1,0,0,0,0,0,0),
upper_bound=c(10,10,0.1,10,100000000,25,45))
## Test the model solves
f <- create_lik(parTab, data, NULL, t=t_long)
parTab
for(run in all_runs){
chains <- load_mcmc_chains(paste0(top_wd, "/chains/",run),parTab,TRUE,10,mcmcPars2["adaptive_period"])
tmp_chain <- as.data.frame(chains[[2]])
tmp_chain$sampno <- 1:nrow(tmp_chain)
tmp_chain$run <- run
tmp_chain <- reshape2::melt(tmp_chain, id.vars=c("sampno","run"))
all_chains <- rbind(all_chains, tmp_chain)
}
ggplot(all_chains) +
geom_density(aes(x=value,fill=run), alpha=0.5) +
facet_wrap(~variable,scales="free") + theme_bw()
library(ggplot2)
ggplot(all_chains) +
geom_density(aes(x=value,fill=run), alpha=0.5) +
facet_wrap(~variable,scales="free") + theme_bw()
setwd("~/Documents/GitHub/gupta_model_check/chains2/prior_only_me/")
chain <- read.csv("prior_only_me_1_multivariate_chain.csv")
plot(coda::as.mcmc(chain))
setwd("~/Documents/GitHub/gupta_model_check/chains2/prior_only_lourenco2//")
chain <- read.csv("prior_only_lourenco2_1_multivariate_chain.csv")
plot(coda::as.mcmc(chain))
setwd("~/Documents/GitHub/gupta_model_check/chains2/fitting_me/")
setwd("~/Documents/GitHub/gupta_model_check/chains2/fitting_me/")
chain <- read.csv("fitting_me_1_univariate_chain.csv")
plot(coda::as.mcmc(chain))
setwd("~/Documents/GitHub/gupta_model_check/chains2/fitting_me/")
chain <- read.csv("fitting_me_1_univariate_chain.csv")
plot(coda::as.mcmc(chain))
chain <- read.csv("fitting_me_2_univariate_chain.csv")
plot(coda::as.mcmc(chain))
setwd("~/Documents/GitHub/gupta_model_check/chains/fitting_lourenco1/")
setwd("~/Documents/GitHub/gupta_model_check/chains2/fitting_lourenco1/")
chain <- read.csv("fitting_lourenco1_1_multivariate_chain.csv")
chain <- read.csv("fitting_lourenco1_1_univariate_chain.csv")
plot(coda::as.mcmc(chain))
setwd("~/Documents/GitHub/gupta_model_check/chains2/fitting_me/")
chain <- read.csv("fitting_me_2_univariate_chain.csv")
plot(coda::as.mcmc(chain))
setwd("~/Documents/GitHub/gupta_model_check/chains2/fitting_me/")
chain <- read.csv("fitting_me_3_univariate_chain.csv")
plot(coda::as.mcmc(chain))
